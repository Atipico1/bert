{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "import json, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5e84aef1c044e7b30e00a3736f4b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "json_file_list = [os.path.join('newspaper_2023', fp) for fp in os.listdir('newspaper_2023') if fp.endswith('.json')]\n",
    "cnt = 0\n",
    "texts = []\n",
    "for json_file in tqdm(json_file_list):\n",
    "    with open(json_file, 'r', encoding='utf-8-sig') as f:\n",
    "        data = json.load(f)[\"document\"]\n",
    "        for d in data:\n",
    "            text = \" \".join([i['form'] for i in d['paragraph']])\n",
    "            texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1023431"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c42c56e5bd4836b18c7216fa9eeb57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1023431 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023431\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "total_output = []\n",
    "for text in tqdm(texts):\n",
    "    if len(text.split()) > 400:\n",
    "        splited_output = text_splitter.split_text(text)\n",
    "        total_output.extend(splited_output)\n",
    "    else:\n",
    "        total_output.append(text)\n",
    "print(len(total_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "news_dataset = Dataset.from_dict({\"text\": total_output, \"subset\": [\"2023년_뉴스_모두의말뭉치\"]*len(total_output)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "new_train_dataset = concatenate_datasets([dataset[\"train\"], news_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f2221444bb41a0842fdc2d67267c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/138 shards):   0%|          | 0/73171640 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b691569ddb44358718f6b83b101bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DatasetDict({\"train\": new_train_dataset,\n",
    "             \"test\": dataset[\"test\"]}).save_to_disk(\"corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Atipico1/korean_corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['subset', 'text'],\n",
       "        num_rows: 72148207\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['subset', 'text'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"] = dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"dataset/korean_corpus_cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"糞\".isalnum()り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIRAGANA\n",
    "KATAKANA\n",
    "CJK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CJK'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicodedata.name(\"糞\").split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LATIN SMALL LETTER L WITH STROKE'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "unicodedata.name(\"ł\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KATAKANA LETTER HE'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "unicodedata.name(\"ヘ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LATIN SMALL LETTER A'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicodedata.name(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HANGUL SYLLABLE A'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicodedata.name(\"아\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CJK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KATAKANA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'apple' appears more than 30% of the time.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def detect_frequent_word(s, threshold_percentage):\n",
    "    \"\"\"\n",
    "    문자열을 단어 단위로 쪼개고, 특정 단어가 전체의 일정 비율 이상을 차지하는지 감지하는 함수\n",
    "\n",
    "    :param s: 입력 문자열\n",
    "    :param threshold_percentage: 비율 임계값 (예: 30은 30%)\n",
    "    :return: (bool, str), 비율을 초과하는 단어가 있는지 여부와 그 단어\n",
    "    \"\"\"\n",
    "    words = s.split()\n",
    "    total_words = len(words)\n",
    "    \n",
    "    if total_words == 0:\n",
    "        return False, None\n",
    "\n",
    "    word_counts = Counter(words)\n",
    "    \n",
    "    for word, count in word_counts.items():\n",
    "        if count / total_words * 100 >= threshold_percentage:\n",
    "            return True, word\n",
    "\n",
    "    return False, None\n",
    "\n",
    "input_string = \"apple orange banana apple apple grape apple orange apple apple\"\n",
    "threshold_percentage = 30\n",
    "\n",
    "result, frequent_word = detect_frequent_word(input_string, threshold_percentage)\n",
    "\n",
    "if result:\n",
    "    print(f\"The word '{frequent_word}' appears more than {threshold_percentage}% of the time.\")\n",
    "else:\n",
    "    print(f\"No word appears more than {threshold_percentage}% of the time.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"국내청년국쳥년모라다가교육계에집어넛코각종학문교수야인재양성인양셩연후에학계주인학계쥬인되것도대장부쟝부의일이로다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
